{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **AdaBoost**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "All media | Median molecules log transformed"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from joblib import dump\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from math import sqrt\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import max_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading and transformation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"./ALL_trainingdata.csv\", sep='\\t')\n",
        "\n",
        "col = []\n",
        "for column in data.columns:\n",
        "    col.append(column)\n",
        "\n",
        "target_col = col[2]\n",
        "features = col[3:len(col)]\n",
        "\n",
        "#scaler_x = MinMaxScaler(feature_range=(0,1))\n",
        "#scaler_y = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "X = data[features].values\n",
        "y = data[target_col].values\n",
        "y = np.log1p(y)\n",
        "y = np.reshape(y, (-1,1))\n",
        "\n",
        "#X = scaler_x.fit_transform(X)\n",
        "#y = scaler_y.fit_transform(y)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model configuration and training"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from tpot.builtins import StackingEstimator\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.linear_model import LassoLarsCV\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.pipeline import make_pipeline, make_union\n",
        "from sklearn.preprocessing import MaxAbsScaler, RobustScaler, Normalizer\n",
        "\n",
        "base = make_pipeline(\n",
        "    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n",
        "    StackingEstimator(estimator=LinearSVR(C=0.01, dual=True, epsilon=0.001, loss=\"epsilon_insensitive\", tol=0.1)),\n",
        "    MaxAbsScaler(),\n",
        "    StackingEstimator(estimator=RidgeCV()),\n",
        "    Normalizer(norm=\"l2\"),\n",
        "    StackingEstimator(estimator=LinearSVR(C=0.5, dual=False, epsilon=0.1, loss=\"squared_epsilon_insensitive\", tol=0.1)),\n",
        "    StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=False, max_features=0.4, min_samples_leaf=2, min_samples_split=4, n_estimators=100)),\n",
        "    MinMaxScaler(),    \n",
        "    StackingEstimator(estimator=RidgeCV()),\n",
        "    StackingEstimator(estimator=LinearSVR(C=5.0, dual=True, epsilon=0.1, loss=\"epsilon_insensitive\", tol=0.0001)),\n",
        "    StackingEstimator(estimator=RidgeCV()),\n",
        "    StackingEstimator(estimator=SGDRegressor()),\n",
        "    RobustScaler(),\n",
        "    StackingEstimator(estimator=LinearSVR(C=15.0, dual=True, epsilon=0.01, loss=\"epsilon_insensitive\", tol=0.1)),\n",
        "    StackingEstimator(estimator=ElasticNetCV(l1_ratio=0.75, tol=0.001)),\n",
        "    StackingEstimator(estimator=XGBRegressor(learning_rate=0.1, max_depth=1, min_child_weight=6, n_estimators=100, nthread=1, objective=\"reg:squarederror\", subsample=0.6500000000000001)),\n",
        "    MinMaxScaler(),\n",
        "    StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=False, max_features=0.2, min_samples_leaf=2, min_samples_split=4, n_estimators=100)),\n",
        "    StackingEstimator(estimator=LinearSVR(C=5.0, dual=True, epsilon=0.1, loss=\"epsilon_insensitive\", tol=0.0001)),\n",
        "    MaxAbsScaler(),\n",
        "    RandomForestRegressor(bootstrap=False, max_features=0.05, min_samples_leaf=1, min_samples_split=4, n_estimators=100)\n",
        ")\n",
        "\n",
        "parameters = {'test_size': 0.25,\n",
        "              'base_estimator': base,\n",
        "              'n_estimators': 100,            #default = 50\n",
        "              'learning_rate': 0.3,          #default = 1.0\n",
        "              'loss': 'linear',\n",
        "              'random_state': 9             #default = None\n",
        "             }\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=parameters['test_size'], random_state=9)\n",
        "\n",
        "model = AdaBoostRegressor(base_estimator=parameters['base_estimator'],\n",
        "                          n_estimators=parameters['n_estimators'],\n",
        "                          learning_rate=parameters['learning_rate'],\n",
        "                          loss=parameters['loss'],\n",
        "                          random_state=parameters['random_state'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train.ravel())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#y_rescaled = scaler_y.inverse_transform(y_valid)\n",
        "y_rescaled = y_valid\n",
        "\n",
        "predict_valid = model.predict(X_valid)\n",
        "predict_valid = np.reshape(predict_valid, (-1,1))\n",
        "#predict_valid = scaler_y.inverse_transform(predict_valid)\n",
        "\n",
        "baseline_preds = y_rescaled[:,target_col.index(\"Median molecules per cell\")]\n",
        "baseline_errors = abs(baseline_preds - y_rescaled)\n",
        "errors = abs(predict_valid - y_rescaled)\n",
        "mape = 100 * (errors / y_rescaled)\n",
        "accuracy = 100 - np.mean(mape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average baseline error: \", round(np.mean(baseline_errors),2))\n",
        "print(\"Mean absolute error: \", round(np.mean(errors),2))\n",
        "print(\"Accuracy: \", round(accuracy, 2), \"%\", \"\\n\")\n",
        "\n",
        "print(\"Explained variance regression score: \", explained_variance_score(y_rescaled, predict_valid))\n",
        "print(\"R2 score: \", r2_score(y_rescaled, predict_valid), \"\\n\")\n",
        "\n",
        "print(\"Maximum residual error: \", max_error(y_rescaled, predict_valid))\n",
        "print(\"Median absolute error: \", median_absolute_error(y_rescaled, predict_valid))\n",
        "print(\"Mean absolute error: \", mean_absolute_error(y_rescaled, predict_valid))\n",
        "print(\"Mean squared error: \", mean_squared_error(y_rescaled, predict_valid))\n",
        "print(\"Root mean squared error:\", sqrt(mean_squared_error(y_rescaled, predict_valid)))\n",
        "print(\"Mean squared logarithmic error: \", mean_squared_log_error(y_rescaled, predict_valid))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation between experimental data and predicted values"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pearson = stats.pearsonr(y_rescaled.ravel(), predict_valid.ravel())\n",
        "spearman = stats.spearmanr(y_rescaled.ravel(), predict_valid.ravel())\n",
        "\n",
        "print('Pearson\\'s r:', pearson[0], 'p-value:', pearson[1])\n",
        "print('Spearman\\'s r:', spearman[0], 'p-value:', spearman[1], '\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data = pd.DataFrame()\n",
        "plot_data['Known abundance'] = y_rescaled.ravel()\n",
        "plot_data['Predicted abundance'] = predict_valid.ravel()\n",
        "\n",
        "sns.regplot(x='Known abundance', y='Predicted abundance', data=plot_data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicted values"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "predict_valid = np.expm1(predict_valid)\n",
        "y_rescaled = np.expm1(y_rescaled)\n",
        "\n",
        "fmt = '%-8s%-20s%s'\n",
        "\n",
        "print(fmt % ('', 'Eval data', 'Prediction'))\n",
        "for i, (eval_row, pred_row) in enumerate(zip(y_rescaled, predict_valid)):\n",
        "    print(fmt % (i, eval_row, pred_row))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model testing with ecYeast7"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "yeast7 = pd.read_csv(\"./testingdata.csv\", sep='\\t')\n",
        "\n",
        "col_test = []\n",
        "for column in yeast7.columns:\n",
        "    col_test.append(column)\n",
        "\n",
        "test_known = col_test[2]\n",
        "test_features = col_test[3:len(col)]\n",
        "\n",
        "#scaler_x_test = MinMaxScaler(feature_range=(0,1))\n",
        "#scaler_y_test = MinMaxScaler(feature_range=(0,1))\n",
        "\n",
        "X_test = yeast7[test_features].values\n",
        "#X_test = yeast7[selected].values\n",
        "y_test = yeast7[test_known].values\n",
        "y_test = np.log1p(y_test)\n",
        "y_test = np.reshape(y_test, (-1,1))\n",
        "\n",
        "#X_test = scaler_x_test.fit_transform(X_test)\n",
        "#y_test = scaler_y_test.fit_transform(y_test)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#test_rescaled = scaler_y_test.inverse_transform(y_test)\n",
        "test_rescaled = y_test\n",
        "\n",
        "predict_yeast7 = model.predict(X_test)\n",
        "predict_yeast7 = np.reshape(predict_yeast7, (-1,1))\n",
        "#predict_yeast7 = scaler_y.inverse_transform(predict_yeast7)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_preds_test = test_rescaled[:,test_known.index(\"Median molecules per cell\")]\n",
        "baseline_errors_test = abs(baseline_preds_test - test_rescaled)\n",
        "errors_test = abs(predict_yeast7 - test_rescaled)\n",
        "mape_test = 100 * (errors_test / test_rescaled)\n",
        "accuracy_test = 100 - np.mean(mape_test)\n",
        "\n",
        "print(\"Average baseline error: \", round(np.mean(baseline_errors_test),2))\n",
        "print(\"Mean absolute error: \", round(np.mean(errors_test),2))\n",
        "print(\"Accuracy: \", round(accuracy_test, 2), \"%\", \"\\n\")\n",
        "\n",
        "print(\"Explained variance regression score: \", explained_variance_score(test_rescaled, predict_yeast7))\n",
        "print(\"R2 score: \", r2_score(test_rescaled, predict_yeast7), '\\n')\n",
        "\n",
        "print(\"Maximum residual error: \", max_error(test_rescaled, predict_yeast7))\n",
        "print(\"Median absolute error: \", median_absolute_error(test_rescaled, predict_yeast7))\n",
        "print(\"Mean absolute error: \", mean_absolute_error(test_rescaled, predict_yeast7))\n",
        "print(\"Mean squared error: \", mean_squared_error(test_rescaled, predict_yeast7))\n",
        "print(\"Root mean squared error:\", sqrt(mean_squared_error(test_rescaled, predict_yeast7)))\n",
        "print(\"Mean squared logarithmic error: \", mean_squared_log_error(test_rescaled, predict_yeast7))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pearson = stats.pearsonr(y_rescaled.ravel(), predict_valid.ravel())\n",
        "spearman = stats.spearmanr(y_rescaled.ravel(), predict_valid.ravel())\n",
        "\n",
        "print('Pearson\\'s r:', pearson[0], 'p-value:', pearson[1])\n",
        "print('Spearman\\'s r:', spearman[0], 'p-value:', spearman[1])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data = pd.DataFrame()\n",
        "plot_data['Known abundance'] = test_rescaled.ravel()\n",
        "plot_data['Predicted abundance'] = predict_yeast7.ravel()\n",
        "\n",
        "sns.regplot(x='Known abundance', y='Predicted abundance', data=plot_data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "predict_yeast7 = np.expm1(predict_yeast7)\n",
        "test_rescaled = np.expm1(test_rescaled)\n",
        "\n",
        "fmt = '%-8s%-20s%s'\n",
        "\n",
        "print(fmt % ('', 'Known abundance', 'Prediction'))\n",
        "for i, (eval_row, pred_row) in enumerate(zip(yeast7['Median molecules per cell'], predict_yeast7)):\n",
        "    print(fmt % (i, eval_row, pred_row))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ecYeast8 protein prediction"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ecyeast8 = pd.read_csv(\"./ALL_predictiondata.csv\", sep='\\t')\n",
        "\n",
        "ecy8_col_test = []\n",
        "for column in ecyeast8.columns:\n",
        "    ecy8_col_test.append(column)\n",
        "\n",
        "ecy8_pred_unknown = ecy8_col_test[2]\n",
        "ecy8_pred_features = ecy8_col_test[3:len(col)]\n",
        "\n",
        "X_pred = ecyeast8[ecy8_pred_features].values\n",
        "y_pred = ecyeast8[ecy8_pred_unknown].values\n",
        "y_pred = np.log1p(y_pred)\n",
        "y_pred = np.reshape(y_pred, (-1,1))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "predict_ecyeast8 = model.predict(X_pred)\n",
        "predict_ecyeast8 = np.reshape(predict_ecyeast8, (-1,1))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "predict_ecyeast8 = np.expm1(predict_ecyeast8)\n",
        "\n",
        "fmt = '%-8s%-20s'\n",
        "\n",
        "print(fmt % ('', 'Prediction'))\n",
        "for i, pred_row in enumerate(predict_ecyeast8):\n",
        "    print(fmt % (i, pred_row))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prot_list = predict_ecyeast8.tolist()\n",
        "output = open(\"pred_ecYeast8_ALL.txt\", \"w\")\n",
        "for prot in prot_list:\n",
        "    output.write(str(prot)+'\\n')\n",
        "output.close()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nteract": {
      "version": "0.24.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}