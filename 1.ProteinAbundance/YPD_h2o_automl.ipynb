{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **H2O AutoML Regression**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "YPD medium | Median molecules log transformed"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import max_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import r2_score"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "h2o.init()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading and transformation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"./YPD_trainingdata.csv\", sep='\\t')\n",
        "data['Median molecules per cell'] = np.log1p(data['Median molecules per cell'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "data = h2o.H2OFrame(data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "no_id = data.drop(['Protein(Ensembl)', 'Standard Name'])\n",
        "\n",
        "x = no_id.columns\n",
        "y = 'Median molecules per cell'\n",
        "x.remove(y)\n",
        "\n",
        "split = no_id.split_frame(ratios = [0.75], seed = 9)\n",
        "train = split[0]\n",
        "valid = split[1]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model configuration and training"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = H2OAutoML(max_runtime_secs = 21600,\n",
        "                  max_models = None,\n",
        "                  nfolds = 10,\n",
        "                  #seed = 9,\n",
        "                  project_name = \"H2O_AutoML_Regression\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(x = x, y = y, training_frame = train, leaderboard_frame = valid)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model.leaderboard"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "y_valid = valid[y]\n",
        "y_valid = y_valid.as_data_frame()\n",
        "y_valid = np.array(y_valid)\n",
        "\n",
        "predict_valid = model.predict(valid)\n",
        "predict_valid = predict_valid.as_data_frame()\n",
        "predict_valid = np.array(predict_valid)\n",
        "\n",
        "baseline_preds = y_valid[:,y.index(\"Median molecules per cell\")]\n",
        "baseline_errors = abs(baseline_preds - y_valid)\n",
        "errors = abs(predict_valid - y_valid)\n",
        "mape = 100 * (errors / y_valid)\n",
        "accuracy = 100 - np.mean(mape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.leader.model_performance(valid))\n",
        "print(\"----------\", '\\n')\n",
        "\n",
        "print(\"Average baseline error: \", round(np.mean(baseline_errors),2))\n",
        "print(\"Mean absolute error: \", round(np.mean(errors),2))\n",
        "print(\"Accuracy: \", round(accuracy, 2), \"%\", \"\\n\")\n",
        "\n",
        "print(\"Explained variance regression score: \", explained_variance_score(y_valid, predict_valid))\n",
        "print(\"R2 score: \", r2_score(y_valid, predict_valid), '\\n')\n",
        "\n",
        "print(\"Maximum residual error: \", max_error(y_valid, predict_valid))\n",
        "print(\"Median absolute error: \", median_absolute_error(y_valid, predict_valid))\n",
        "print(\"Mean absolute error: \", mean_absolute_error(y_valid, predict_valid))\n",
        "print(\"Mean squared error: \", mean_squared_error(y_valid, predict_valid))\n",
        "print(\"Root mean squared error:\", sqrt(mean_squared_error(y_valid, predict_valid)))\n",
        "print(\"Mean squared logarithmic error: \", mean_squared_log_error(y_valid, predict_valid))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation between experimental data and predicted values"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "predict_valid = np.expm1(predict_valid)\n",
        "y_valid = np.expm1(y_valid)\n",
        "\n",
        "pearson = stats.pearsonr(y_valid.ravel(), predict_valid.ravel())\n",
        "spearman = stats.spearmanr(y_valid.ravel(), predict_valid.ravel())\n",
        "\n",
        "print('Pearson\\'s r:', pearson[0], 'p-value:', pearson[1])\n",
        "print('Spearman\\'s r:', spearman[0], 'p-value:', spearman[1], '\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data = pd.DataFrame()\n",
        "plot_data['Known abundance'] = y_valid.ravel()\n",
        "plot_data['Predicted abundance'] = predict_valid.ravel()\n",
        "\n",
        "sns.regplot(x='Known abundance', y='Predicted abundance', data=plot_data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicted values"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "fmt = '%-8s%-20s%s'\n",
        "\n",
        "print(fmt % ('', 'Eval data', 'Prediction'))\n",
        "for i, (eval_row, pred_row) in enumerate(zip(y_valid, predict_valid)):\n",
        "    print(fmt % (i, eval_row, pred_row))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ecYeast8 protein prediction"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "yeast8 = pd.read_csv(\"./YPD_predictiondata.csv\", sep='\\t')\n",
        "yeast8['Median molecules per cell'] = np.log1p(yeast8['Median molecules per cell'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "yeast8 = h2o.H2OFrame(yeast8)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "yeast8_no_id = yeast8.drop(['Protein(Ensembl)', 'Standard Name'])\n",
        "\n",
        "x = yeast8_no_id.columns\n",
        "y = 'Median molecules per cell'\n",
        "x.remove(y)\n",
        "\n",
        "test = yeast8_no_id"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = test[y]\n",
        "y_test = y_test.as_data_frame()\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "predict_valid = model.predict(test)\n",
        "predict_valid = predict_valid.as_data_frame()\n",
        "predict_valid = np.array(predict_valid)\n",
        "\n",
        "baseline_preds = y_test[:,y.index(\"Median molecules per cell\")]\n",
        "baseline_errors = abs(baseline_preds - y_test)\n",
        "errors = abs(predict_valid - y_test)\n",
        "mape = 100 * (errors / y_test)\n",
        "accuracy = 100 - np.mean(mape)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.leader.model_performance(test))\n",
        "print(\"----------\", '\\n')\n",
        "\n",
        "print(\"Average baseline error: \", round(np.mean(baseline_errors),2))\n",
        "print(\"Mean absolute error: \", round(np.mean(errors),2))\n",
        "print(\"Accuracy: \", round(accuracy, 2), \"%\", \"\\n\")\n",
        "\n",
        "print(\"Explained variance regression score: \", explained_variance_score(y_test, predict_valid))\n",
        "print(\"R2 score: \", r2_score(y_test, predict_valid), '\\n')\n",
        "\n",
        "print(\"Maximum residual error: \", max_error(y_test, predict_valid))\n",
        "print(\"Median absolute error: \", median_absolute_error(y_test, predict_valid))\n",
        "print(\"Mean absolute error: \", mean_absolute_error(y_test, predict_valid))\n",
        "print(\"Mean squared error: \", mean_squared_error(y_test, predict_valid))\n",
        "print(\"Root mean squared error:\", sqrt(mean_squared_error(y_test, predict_valid)))\n",
        "print(\"Mean squared logarithmic error: \", mean_squared_log_error(y_test, predict_valid))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation between experimental data and predicted values"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.expm1(y_test)\n",
        "predict_valid = np.expm1(predict_valid)\n",
        "\n",
        "\n",
        "pearson = stats.pearsonr(y_test.ravel(), predict_valid.ravel())\n",
        "spearman = stats.spearmanr(y_test.ravel(), predict_valid.ravel())\n",
        "\n",
        "print('Pearson\\'s r:', pearson[0], 'p-value:', pearson[1])\n",
        "print('Spearman\\'s r:', spearman[0], 'p-value:', spearman[1], '\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data = pd.DataFrame()\n",
        "plot_data['Known abundance'] = y_test.ravel()\n",
        "plot_data['Predicted abundance'] = predict_valid.ravel()\n",
        "\n",
        "sns.regplot(x='Known abundance', y='Predicted abundance', data=plot_data)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicted values"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "fmt = '%-8s%-20s%s'\n",
        "\n",
        "print(fmt % ('', 'Eval data', 'Prediction'))\n",
        "for i, (eval_row, pred_row) in enumerate(zip(y_test, predict_valid)):\n",
        "    print(fmt % (i, eval_row, pred_row))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nteract": {
      "version": "0.24.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}